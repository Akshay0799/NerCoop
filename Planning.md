

**Task 1: Understanding NER**
(2 weeks? - May 1-15 2022)
- Understand the problem and typical approaches followed 
- Learn to use a few existing NLP libraries   
    1. with off the shelf models (e.g., spacy, flair, stanza, huggingface)  
- identify some problem areas (e.g., sensitivity to certain kinds of inputs, not doing well for some NE tags compared to others etc)   


**Task 2: Understanding various topics in NER context** 
(2 weeks? -May 15-30 2022)  
- weak supervision (familiarity with libraries such as: skweak, knodle, flying squid)  
- domain adaptation, few short learning  
- prompt based learning

**Task 3: Multilingual NER exercise**  
(2 weeks? - June 1-15 2022)  
- Fine-tuning a BERT model for multiple languages and comparing   
- goal: to familiarize with the training, tuning, comparisons process  
- can use multiconer dataset or anyother.  
-libraries that support training and fine-tuning language models for NER such as [tner](https://github.com/asahi417/tner) , [NERDA](https://github.com/ebanalyse/NERDA/tree/main/src/NERDA), [ACE](https://github.com/Alibaba-NLP/ACE), Flair, Spacy etc  

**Task 4: ** 







