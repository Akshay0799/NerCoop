

**Task 1: Understanding NER**
(2 weeks? - May 1-15 2022)
- Understand the problem and typical approaches followed 
- Learn to use a few existing NLP libraries   
    1. with off the shelf models (e.g., spacy, flair, stanza, huggingface)  
- identify some problem areas (e.g., sensitivity to certain kinds of inputs, not doing well for some NE tags compared to others etc)   


**Task 2: Understanding various topics in NER context** 
(2 weeks? -May 15-30 2022)  
- weak supervision (familiarity with libraries such as: skweak, knodle, flying squid)  
- domain adaptation, few short learning  
- prompt based learning

**Task 3: Multilingual NER exercise**  
(2 weeks? - June 1-15 2022)  
- Fine-tuning a BERT model for multiple languages and comparing   
- goal: to familiarize with the training, tuning, comparisons process  
- can use multiconer dataset or anyother.  
-libraries that support training and fine-tuning language models for NER such as [tner](https://github.com/asahi417/tner) , [NERDA](https://github.com/ebanalyse/NERDA/tree/main/src/NERDA), [ACE](https://github.com/Alibaba-NLP/ACE), Flair, Spacy etc  

**Task 4: Under-represented tags**  
Exploring methods to get better at predicting NE tags that are under-represented in the training set
- will data augmentation work?
- some other way? 
(2 weeks? - June 15-30 2022)

**Task 5: Domain adaptation**
(July 2022)
Can we develop methods to adopt NER in two scenarios: 
- same tag set, but a new domain 
- slightly different tagset, a new domain

**Task 7: Concluding the project**  
Final round of experiments, Wrap up, report writing and code cleanup  
(August 2022)






